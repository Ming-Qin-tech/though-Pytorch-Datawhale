{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87cca298",
   "metadata": {},
   "source": [
    "## 6.1 自定义loss函数总结\n",
    "- 以函数方式\n",
    "- 更常用的，作为一个神经网络层，定义一个神经网络层，继承自nn.Module, loss计算方式定义在forward方法中"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9580d49",
   "metadata": {},
   "source": [
    "- 在自定义损失函数时，涉及到数学运算时，我们最好全程使用PyTorch提供的张量计算接口，这样就不需要我们实现自动求导功能并且我们可以直接调用cuda，使用numpy或者scipy的数学运算时，操作会有些麻烦，大家可以自己下去进行探索。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd7591",
   "metadata": {},
   "source": [
    "- 科学研究中，我们往往会提出全新的损失函数来提升模型的表现，这时我们既无法使用PyTorch自带的损失函数，也没有相关的博客供参考，此时自己实现损失函数就显得更为重要了。\n",
    "------\n",
    "### 以函数方式定义\n",
    "- 事实上，**损失函数仅仅是一个函数而已**，因此我们可以通过直接以函数定义的方式定义一个自己的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5eea30d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T13:25:35.937725Z",
     "start_time": "2022-03-19T13:25:35.933096Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328dff44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T13:25:36.664195Z",
     "start_time": "2022-03-19T13:25:36.656474Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_loss(output, target):\n",
    "    loss = torch.mean((output - target)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f739ae0",
   "metadata": {},
   "source": [
    "虽然以函数定义的方式很简单，但是以类方式定义更加常用，在以类方式定义损失函数时，我们如果看每一个损失函数的继承关系我们就可以发现`Loss`函数部分继承自`_loss`, 部分继承自`_WeightedLoss`, 而`_WeightedLoss`继承自`_loss`，` _loss`继承自 **nn.Module**。我们可以**将其当作神经网络的一层来对待**，同样地，我们的损失函数类就需要继承自**nn.Module**类，在下面的例子中我们以DiceLoss为例向大家讲述。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770f7f7c",
   "metadata": {},
   "source": [
    "$$\n",
    "DSC = \\frac{2|X∩Y|}{|X|+|Y|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72252b1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T13:30:41.653684Z",
     "start_time": "2022-03-19T13:30:41.620980Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'targets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 使用方法\u001b[39;00m\n\u001b[1;32m     14\u001b[0m criterion \u001b[38;5;241m=\u001b[39m DiceLoss()\n\u001b[0;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(\u001b[38;5;28minput\u001b[39m, \u001b[43mtargets\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'targets' is not defined"
     ]
    }
   ],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None,size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, inputs,targets,smooth=1):\n",
    "        inputs = F.sigmoid(inputs)\n",
    "        inputs=inputs.view(-1)\n",
    "        targets = targets.view(-1) #如果是torch.view(-1)，则原张量会变成一维的结构。\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2. * intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "        return 1 -dice\n",
    "    \n",
    "# 使用方法\n",
    "criterion = DiceLoss()\n",
    "loss = criterion(input, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65860864",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T13:31:10.053024Z",
     "start_time": "2022-03-19T13:31:09.954835Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1304665520.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [12]\u001b[0;36m\u001b[0m\n\u001b[0;31m    --------------------------------------------------------------------\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 除此之外，常见的损失函数还有BCE-Dice Loss，Jaccard/Intersection over Union (IoU) Loss，Focal Loss......\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        intersection = (inputs * targets).sum()                     \n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "        \n",
    "        return Dice_BCE\n",
    "--------------------------------------------------------------------\n",
    "    \n",
    "class IoULoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(IoULoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        intersection = (inputs * targets).sum()\n",
    "        total = (inputs + targets).sum()\n",
    "        union = total - intersection \n",
    "        \n",
    "        IoU = (intersection + smooth)/(union + smooth)\n",
    "                \n",
    "        return 1 - IoU\n",
    "--------------------------------------------------------------------\n",
    "    \n",
    "ALPHA = 0.8\n",
    "GAMMA = 2\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, alpha=ALPHA, gamma=GAMMA, smooth=1):\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        BCE_EXP = torch.exp(-BCE)\n",
    "        focal_loss = alpha * (1-BCE_EXP)**gamma * BCE\n",
    "                       \n",
    "        return focal_loss\n",
    "# 更多的可以参考链接1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e2e878",
   "metadata": {},
   "source": [
    "------------------\n",
    "### 6.2 动态调整学习率\n",
    "- 学习率的选择是深度学习中一个困扰人们许久的问题，学习速率设置过小，会极大降低收敛速度，增加训练时间；学习率太大，可能导致参数在最优解两侧来回振荡。但是当我们选定了一个合适的学习率后，经过许多轮的训练后，可能会出现准确率震荡或loss不再下降等情况，说明当前学习率已不能满足模型调优的需求。此时我们就可以通过一个适当的学习率衰减策略来改善这种现象，提高我们的精度。\n",
    "- 这种设置方式在PyTorch中被称为**scheduler**，也是我们本节所研究的对象。\n",
    "----------\n",
    "- 学习目标：\n",
    "    - 如何根据需要选取已有的学习率调整策略\n",
    "    - 如何自定义设置学习调整策略并实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fae6437",
   "metadata": {},
   "source": [
    "#### 6.2.1 使用官方scheduler\n",
    "- 使用官方提供的API：\n",
    "    - 在训练神经网络的过程中，学习率是最重要的超参数之一，作为当前较为流行的深度学习框架，PyTorch已经在**`torch.optim.lr_scheduler`**为我们封装好了一些动态调整学习率的方法供我们使用，如下面列出的这些scheduler。\n",
    "\n",
    "+ [`lr_scheduler.LambdaLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LambdaLR.html#torch.optim.lr_scheduler.LambdaLR)\n",
    "+ [`lr_scheduler.MultiplicativeLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.MultiplicativeLR.html#torch.optim.lr_scheduler.MultiplicativeLR)\n",
    "+ [`lr_scheduler.StepLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR)\n",
    "+ [`lr_scheduler.MultiStepLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.MultiStepLR.html#torch.optim.lr_scheduler.MultiStepLR)\n",
    "+ [`lr_scheduler.ExponentialLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ExponentialLR.html#torch.optim.lr_scheduler.ExponentialLR)\n",
    "+ [`lr_scheduler.CosineAnnealingLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#torch.optim.lr_scheduler.CosineAnnealingLR)\n",
    "+ [`lr_scheduler.ReduceLROnPlateau`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html#torch.optim.lr_scheduler.ReduceLROnPlateau)\n",
    "+ [`lr_scheduler.CyclicLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CyclicLR.html#torch.optim.lr_scheduler.CyclicLR)\n",
    "+ [`lr_scheduler.OneCycleLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html#torch.optim.lr_scheduler.OneCycleLR)\n",
    "+ [`lr_scheduler.CosineAnnealingWarmRestarts`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts)\n",
    "--------\n",
    "- 根据官方文档学习使用官方API\n",
    "    - 关于如何使用这些动态调整学习率的策略，`PyTorch`官方也很人性化的给出了使用实例代码帮助大家理解\n",
    "    - 我们在使用官方给出的`torch.optim.lr_scheduler`时，需要将`scheduler.step()`放在`optimizer.step()`后面进行使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f45669e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T13:49:52.324579Z",
     "start_time": "2022-03-19T13:49:52.308835Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3639871327.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [13]\u001b[0;36m\u001b[0m\n\u001b[0;31m    scheduler1 = torch.optim.lr_scheduler...\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 选择一种优化器\n",
    "optimizer =  torch.optim.Adam(...)\n",
    "# 选择上面提到的一种或多种动态调整学习率的方法\n",
    "scheduler1 = torch.optim.lr_scheduler...\n",
    "scheduler2 = torch.optim.lr_scheduler...\n",
    "...\n",
    "schedulern = torch.optim.lr_scheduler...\n",
    "# 进行训练\n",
    "for epoch in range(100):\n",
    "    train(...)\n",
    "    validate(...)\n",
    "    optimizer.step()\n",
    "    #  需要在优化器参数更新之后再动态调整学习率\n",
    "    scheduler1.step()\n",
    "    ...\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514412c7",
   "metadata": {},
   "source": [
    "#### 自定义scheduler\n",
    "- 虽然PyTorch官方给我们提供了许多的API，但是在实验中也有可能碰到需要我们自己定义学习率调整策略的情况，而我们的方法是自定义函数`adjust_learning_rate`来改变`param_group`中`lr`的值，在下面的叙述中会给出一个简单的实现。\n",
    "- 假设我们现在正在做实验，需要学习率每30轮下降为原来的1/10，假设已有的官方API中没有符合我们需求的，那就需要自定义函数来实现学习率的改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63ddaf8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T13:53:38.859076Z",
     "start_time": "2022-03-19T13:53:38.852627Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = args.lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b9618e",
   "metadata": {},
   "source": [
    "- 有了`adjust_learning_rate`函数的定义，在训练的过程就可以调用我们的函数来实现学习率的动态变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d91d3f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T13:55:29.135998Z",
     "start_time": "2022-03-19T13:55:29.129188Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4273724285.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [15]\u001b[0;36m\u001b[0m\n\u001b[0;31m    def adjust_learning_rate(optimizer,...):\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def adjust_learning_rate(optimizer,...):\n",
    "    ...\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = args.lr, momentum = 0.9)\n",
    "    for epoch in range(10):\n",
    "        train(...)\n",
    "        validate(...)\n",
    "        adjust_learning_rate(optimizer, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036990bf",
   "metadata": {},
   "source": [
    "## 6.3 模型微调\n",
    "- 微调：将从源数据集学到的知识迁移到目标数据集上。例如，虽然ImageNet数据集的图像大多跟椅子无关，但在该数据集上训练的模型可以**抽取较通用的图像特征，从而能够帮助识别边缘、纹理、形状和物体组成等**。这些类似的特征**对于识别椅子也可能同样有效**。\n",
    "- 迁移学习的一大应用场景是模型微调（finetune）。简单来说，就是我们先找到一个同类的别人训练好的模型，把别人现成的训练好了的模型拿过来，换成自己的数据，通过训练调整一下参数。 **在PyTorch中提供了许多预训练好的网络模型**（VGG，ResNet系列，mobilenet系列......），这些模型都是**PyTorch官方在相应的大型数据集训练好的**。学习如何进行模型微调，可以方便我们快速使用预训练模型完成自己的任务。\n",
    "-----------\n",
    "- 学习目标：\n",
    "    - 掌握模型微调的流程\n",
    "    - 了解Pytorch提供的常用model\n",
    "    - **掌握如何训练模型的部分层**\n",
    "-----------\n",
    "#### 6.3.1 模型微调的流程\n",
    "1. 在源数据集(如ImageNet数据集)上预训练一个神经网络模型，即源模型(预训练模型)/下载已开源的预训练模型。 \n",
    "2. 创建一个新的神经网络模型，即目标模型。**它复制了源模型上除了输出层外的所有模型设计及其参数**。我们假设这些模型参数包含了源数据集上学习到的知识，且这些知识同样适用于目标数据集。\n",
    "3. 为目标模型添加一个输出⼤小为**⽬标数据集类别个数**的输出层，并随机初始化该层的模型参数。\n",
    "4. 在目标数据集上训练目标模型。我们将从头训练输出层**（只从头训练输出层）**，而其余层的参数都是基于源模型的参数微调得到的。\n",
    "-----------\n",
    "#### 6.3.2 使用已有模型结构\n",
    "- 这里我们以torchvision中的常见模型为例，列出了如何在图像分类任务中使用PyTorch提供的常见模型结构和参数。对于其他任务和网络结构，使用方式是类似的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c530f7e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T14:37:05.966895Z",
     "start_time": "2022-03-19T14:37:00.403229Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/qm/anaconda3/envs/mtorch/lib/python3.8/site-packages/torchvision/models/googlenet.py:46: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 实例化网络\n",
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18()\n",
    "# resnet18 = models.resnet18(pretained=False)  # 等价于上面的表达式\n",
    "alexnet = models.alexnet()\n",
    "vgg16 = models.vgg16()\n",
    "squeezenet = models.squeezenet1_0()\n",
    "densenet = models.densenet161()\n",
    "inception = models.inception_v3()\n",
    "googlenet = models.googlenet()\n",
    "shufflenet = models.shufflenet_v2_x1_0()\n",
    "mobilenet_v2 = models.mobilenet_v3_large()\n",
    "mobilenet_v3_large = models.mobilenet_v3_large()\n",
    "mobilenet_v3_small = models.mobilenet_v3_small()\n",
    "resnext50_32x4d = models.resnext50_32x4d()\n",
    "wide_resnet50_2 = models.wide_resnet50_2()\n",
    "mnasnet = models.mnasnet1_0()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6a760",
   "metadata": {},
   "source": [
    "- 传递`pretrained`参数\n",
    "    - 通过`True` 或者`False`来决定是否使用预训练好的权重，在默认状态下`pretrained = False`，意味着我们不使用预训练得到的权重，当`pretrained = True`，意味着我们将使用在一些数据集上预训练得到的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bc3fc11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T14:42:47.347490Z",
     "start_time": "2022-03-19T14:41:54.363284Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /data/qm/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f498e041c3904d0e9ee57fcf297c61f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /data/qm/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f761b7d296446758e1ccbc1f7c41160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/233M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\n\u001b[1;32m      2\u001b[0m resnet18 \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mresnet18(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m alexnet \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malexnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m squeezenet \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39msqueezenet1_0(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m vgg16 \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mvgg16(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mtorch/lib/python3.8/site-packages/torchvision/models/alexnet.py:67\u001b[0m, in \u001b[0;36malexnet\u001b[0;34m(pretrained, progress, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m model \u001b[38;5;241m=\u001b[39m AlexNet(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pretrained:\n\u001b[0;32m---> 67\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_state_dict_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_urls\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malexnet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/mtorch/lib/python3.8/site-packages/torch/hub.py:591\u001b[0m, in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name)\u001b[0m\n\u001b[1;32m    589\u001b[0m         r \u001b[38;5;241m=\u001b[39m HASH_REGEX\u001b[38;5;241m.\u001b[39msearch(filename)  \u001b[38;5;66;03m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[1;32m    590\u001b[0m         hash_prefix \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m     \u001b[43mdownload_url_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location)\n",
      "File \u001b[0;32m~/anaconda3/envs/mtorch/lib/python3.8/site-packages/torch/hub.py:479\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mfile_size, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m progress,\n\u001b[1;32m    477\u001b[0m           unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 479\u001b[0m         buffer \u001b[38;5;241m=\u001b[39m \u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8192\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mtorch/lib/python3.8/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mtorch/lib/python3.8/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/anaconda3/envs/mtorch/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mtorch/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/mtorch/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "squeezenet = models.squeezenet1_0(pretrained=True)\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "densenet = models.densenet161(pretrained=True)\n",
    "inception = models.inception_v3(pretrained=True)\n",
    "googlenet = models.googlenet(pretrained=True)\n",
    "shufflenet = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "mobilenet_v2 = models.mobilenet_v2(pretrained=True)\n",
    "mobilenet_v3_large = models.mobilenet_v3_large(pretrained=True)\n",
    "mobilenet_v3_small = models.mobilenet_v3_small(pretrained=True)\n",
    "resnext50_32x4d = models.resnext50_32x4d(pretrained=True)\n",
    "wide_resnet50_2 = models.wide_resnet50_2(pretrained=True)\n",
    "mnasnet = models.mnasnet1_0(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d2e0b0",
   "metadata": {},
   "source": [
    "**注意事项：**\n",
    "\n",
    "1. 通常PyTorch模型的扩展为`.pt`或`.pth`，程序运行时会首先检查默认路径中是否有已经下载的模型权重，一旦权重被下载，下次加载就不需要下载了。\n",
    "2. 一般情况下预训练模型的下载会比较慢，我们可以直接通过迅雷或者其他方式去 [这里](https://github.com/pytorch/vision/tree/master/torchvision/models) 查看自己的模型里面`model_urls`，然后手动下载，预训练模型的权重在`Linux`和`Mac`的默认下载路径是用户根目录下的`.cache`文件夹。在`Windows`下就是`C:\\Users\\<username>\\.cache\\torch\\hub\\checkpoint`。我们可以通过使用 [`torch.utils.model_zoo.load_url()`](https://pytorch.org/docs/stable/model_zoo.html#torch.utils.model_zoo.load_url)设置权重的下载地址。\n",
    "3. 如果觉得麻烦，还可以将自己的权重下载下来放到同文件夹下，然后再将参数加载网络。\n",
    "```\n",
    "self.model = models.resnet50(pretrained=False)\n",
    "self.model.load_state_dict(torch.load('./model/resnet50-19c8e357.pth'))\n",
    "```\n",
    "4. **如果中途强行停止下载的话，一定要去对应路径下将权重文件删除干净**，要不然可能会报错。\n",
    "\n",
    "#### 6.3.3 训练特定层\n",
    "- 在默认情况下，参数的属性`.requires_grad = True`，如果我们从头开始训练或微调不需要注意这里。但如果我们正在提取特征并且只想为新初始化的层计算梯度，其他参数不进行改变。那我们就需要通过设置`requires_grad = False`来冻结部分层。在PyTorch官方中提供了这样一个例程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f13d95cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T15:06:08.135110Z",
     "start_time": "2022-03-19T15:06:08.128788Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac271ac1",
   "metadata": {},
   "source": [
    "- 在下面我们仍旧使用`resnet18`为例的将1000类改为4类，但是仅改变最后一层的模型参数，不改变特征提取的模型参数；**注意我们先冻结模型参数的梯度，再对模型输出部分的全连接层进行修改，这样修改后的全连接层的参数就是可计算梯度的**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fdacaf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T15:23:30.423451Z",
     "start_time": "2022-03-19T15:23:30.175301Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "#冻结参数的梯度\n",
    "feature_extract = True\n",
    "model = models.resnet18(pretrained=True)\n",
    "set_parameter_requires_grad(model, feature_extract)\n",
    "# 修改模型\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features=512, out_features=4, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad5c86b",
   "metadata": {},
   "source": [
    "- 之后在训练过程中，model仍会进行梯度回传，但是参数更新则只会发生在fc层。通过设定参数的requires_grad属性，我们完成了指定训练模型的特定层的目标，这对实现模型微调非常重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca165767",
   "metadata": {},
   "source": [
    "### 半精度训练\n",
    "- GPU的性能主要分为两部分：算力和显存，前者决定了显卡计算的速度，后者则决定了显卡可以同时放入多少数据用于计算。\n",
    "- 在可以使用的算力一定的情况下，每次训练能够加载的数据更多（也就是batch size更大），则也可以提高训练效率。\n",
    "- 另外，有时候数据本身也比较大（比如3D图像、视频等），显存较小的情况下可能甚至batch size为1的情况都无法实现。\n",
    "- 因此，合理使用显存也就显得十分重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a031c29c",
   "metadata": {},
   "source": [
    "- 我们观察PyTorch默认的浮点数存储方式用的是torch.float32，小数点后位数更多固然能保证数据的精确性，但绝大多数场景其实并不需要这么精确，只保留一半的信息也不会影响结果，也就是使用torch.float16格式。由于数位减了一半，因此被称为“半精度”\n",
    "- 显然半精度能够减少显存占用，使得显卡可以同时加载更多数据进行计算。本节会介绍如何在PyTorch中设置使用半精度计算。\n",
    "-----------\n",
    "- 学习目标：\n",
    "    - 如何在PyTorch中设置半精度训练\n",
    "    - 使用半精度训练的注意事项\n",
    "----\n",
    "#### 6.4.1 半精度训练的设置\n",
    "- 在PyTorch中使用autocast配置半精度训练，同时需要在下面三处加以设置：\n",
    "    - **import autocast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "032345aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T15:41:07.048981Z",
     "start_time": "2022-03-19T15:41:07.043503Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f27f965",
   "metadata": {},
   "source": [
    "- 模型设置\n",
    "    - 在模型定义中，使用python的装饰器方法，用autocast装饰模型中的forward函数。关于装饰器的使用，可以参考[这里](https://www.cnblogs.com/jfdwd/p/11253925.html)：\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24428d16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T15:43:54.025761Z",
     "start_time": "2022-03-19T15:43:50.408351Z"
    }
   },
   "outputs": [],
   "source": [
    "@autocast()\n",
    "def forward(self, x):\n",
    "    ...\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d027456",
   "metadata": {},
   "source": [
    "- **训练过程**\n",
    "\n",
    "    - 在训练过程中，只需在将数据输入模型及其之后的部分放入“with autocast():“即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "676b0d15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T15:46:46.543403Z",
     "start_time": "2022-03-19T15:46:46.537297Z"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:4\u001b[0;36m\u001b[0m\n\u001b[0;31m    output = model(x)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    " for x in train_loader:\n",
    "\tx = x.cuda()\n",
    "\twith autocast():\n",
    "        output = model(x)\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfe84ae",
   "metadata": {},
   "source": [
    "**注意：**\n",
    "\n",
    "半精度训练**主要适用于数据本身的size比较大（比如说3D图像、视频等）**。当数据本身的size并不大时（比如手写数字MNIST数据集的图片尺寸只有28*28），使用半精度训练则可能不会带来显著的提升。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbda417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mtorch]",
   "language": "python",
   "name": "conda-env-mtorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
